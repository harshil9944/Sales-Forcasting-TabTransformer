{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff75ecb",
   "metadata": {},
   "source": [
    "# Sales Forecasting Using TabTransformer (Notebook Entry Point)\n",
    "\n",
    "This notebook is the main entry point for the project submission.\n",
    "\n",
    "It reproduces the full pipeline that the CLI runs:\n",
    "1) Prepare data (feature engineering + processed parquet/metadata)\n",
    "2) Train model (linreg / xgb / tabtx)\n",
    "3) Evaluate model (metrics + plots)\n",
    "4) Predict on input CSV and write preds.csv\n",
    "\n",
    "Outputs are written under:\n",
    "- data/processed/\n",
    "- artifacts/<model_name>/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a382a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and path setup\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src import utils, data, train, evaluate\n",
    "from src.metrics import metrics_table, MetricsReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bed402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/Chris/Desktop/To Submit/PythonEngineering/FinalProject/local_FinalProject/Sales-Forcasting-TabTransformer/data/raw'),\n",
       " WindowsPath('C:/Users/Chris/Desktop/To Submit/PythonEngineering/FinalProject/local_FinalProject/Sales-Forcasting-TabTransformer/data/processed'),\n",
       " WindowsPath('C:/Users/Chris/Desktop/To Submit/PythonEngineering/FinalProject/local_FinalProject/Sales-Forcasting-TabTransformer/artifacts'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder check\n",
    "ROOT = Path(\".\").resolve()\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = ROOT / \"data\" / \"processed\"\n",
    "ARTIFACTS_DIR = ROOT / \"artifacts\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAW_DIR, PROCESSED_DIR, ARTIFACTS_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2302cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': {'raw_csv': 'data/raw/train.csv',\n",
       "  'train_csv': 'data/raw/train.csv',\n",
       "  'test_csv': 'data/raw/test.csv',\n",
       "  'store_csv': 'data/raw/store.csv',\n",
       "  'processed_dir': 'C:\\\\Users\\\\Chris\\\\Desktop\\\\To Submit\\\\PythonEngineering\\\\FinalProject\\\\local_FinalProject\\\\Sales-Forcasting-TabTransformer\\\\data\\\\processed',\n",
       "  'processed_filename': 'sales_processed.parquet',\n",
       "  'metadata_filename': 'metadata.json',\n",
       "  'artifacts_dir': 'C:\\\\Users\\\\Chris\\\\Desktop\\\\To Submit\\\\PythonEngineering\\\\FinalProject\\\\local_FinalProject\\\\Sales-Forcasting-TabTransformer\\\\artifacts'},\n",
       " 'features': {'target': 'Sales',\n",
       "  'horizon': 1,\n",
       "  'categorical': ['Store',\n",
       "   'DayOfWeek',\n",
       "   'Promo',\n",
       "   'StateHoliday',\n",
       "   'SchoolHoliday'],\n",
       "  'numeric': ['Customers',\n",
       "   'Sales',\n",
       "   'CompetitionDistance',\n",
       "   'Sales_lag_1',\n",
       "   'Sales_lag_7',\n",
       "   'Sales_lag_14',\n",
       "   'Sales_roll7',\n",
       "   'Sales_roll14',\n",
       "   'year',\n",
       "   'month',\n",
       "   'day',\n",
       "   'weekofyear',\n",
       "   'is_weekend']},\n",
       " 'splits': {'strategy': 'ratios',\n",
       "  'train_ratio': 0.6,\n",
       "  'val_ratio': 0.2,\n",
       "  'test_ratio': 0.2},\n",
       " 'training': {'seed': 123,\n",
       "  'batch_size': 32,\n",
       "  'lr': 0.0005,\n",
       "  'weight_decay': 0.0001,\n",
       "  'epochs': 2,\n",
       "  'patience': 1,\n",
       "  'grad_clip': 1.0,\n",
       "  'device': 'cpu',\n",
       "  'amp': False,\n",
       "  'plot_attention': False},\n",
       " 'xgboost': {'n_estimators': 300,\n",
       "  'max_depth': 6,\n",
       "  'learning_rate': 0.1,\n",
       "  'subsample': 0.8,\n",
       "  'colsample_bytree': 0.8},\n",
       " 'linear_regression': {'fit_intercept': True},\n",
       " 'tabtransformer': {'n_layers': 4,\n",
       "  'n_heads': 4,\n",
       "  'd_model': 128,\n",
       "  'ff_dim': 256,\n",
       "  'dropout': 0.1,\n",
       "  'emb_strategy': 'auto'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load config + notebook overrides\n",
    "config_path = ROOT / \"config\" / \"default.yaml\"\n",
    "config = utils.load_yaml(config_path)\n",
    "\n",
    "# can remove for full training\n",
    "config.setdefault(\"training\", {})\n",
    "config[\"training\"].update({\n",
    "    \"epochs\": 2,        \n",
    "    \"batch_size\": 32,\n",
    "    \"patience\": 1,\n",
    "    \"seed\": 123,\n",
    "    \"device\": \"cpu\",\n",
    "    \"amp\": False,\n",
    "})\n",
    "\n",
    "config.setdefault(\"splits\", {})\n",
    "config[\"splits\"].update({\n",
    "    \"strategy\": \"ratios\",\n",
    "    \"train_ratio\": 0.6,\n",
    "    \"val_ratio\": 0.2,\n",
    "    \"test_ratio\": 0.2,\n",
    "})\n",
    "\n",
    "# ensure paths point to repo-local folders\n",
    "config.setdefault(\"paths\", {})\n",
    "config[\"paths\"].update({\n",
    "    \"processed_dir\": str(PROCESSED_DIR),\n",
    "    \"artifacts_dir\": str(ARTIFACTS_DIR),\n",
    "})\n",
    "\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf191147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1025</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1033</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>1041</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>1049</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1057</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Promo StateHoliday  SchoolHoliday  Customers  \\\n",
       "0      1          1  2024-01-01      0            0              0        125   \n",
       "1      1          2  2024-01-02      1            0              0        127   \n",
       "2      1          3  2024-01-03      0            0              0        129   \n",
       "3      1          4  2024-01-04      1            0              0        131   \n",
       "4      1          5  2024-01-05      0            0              0        133   \n",
       "\n",
       "   Sales  CompetitionDistance  \n",
       "0   1025                410.0  \n",
       "1   1033                410.0  \n",
       "2   1041                410.0  \n",
       "3   1049                410.0  \n",
       "4   1057                410.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV creation - users can run without Kaggle\n",
    "records = []\n",
    "base_date = pd.Timestamp(\"2024-01-01\")\n",
    "\n",
    "for store in range(1, 4):\n",
    "    for offset in range(60):  \n",
    "        current_date = base_date + pd.Timedelta(days=offset)\n",
    "        records.append({\n",
    "            \"Store\": store,\n",
    "            \"DayOfWeek\": int(current_date.dayofweek + 1),\n",
    "            \"Date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"Promo\": offset % 2,\n",
    "            \"StateHoliday\": \"0\",\n",
    "            \"SchoolHoliday\": 0,\n",
    "            \"Customers\": 120 + store * 5 + offset * 2,\n",
    "            \"Sales\": 1000 + store * 25 + offset * 8,\n",
    "            \"CompetitionDistance\": 400.0 + store * 10,\n",
    "        })\n",
    "\n",
    "synthetic_df = pd.DataFrame(records)\n",
    "synthetic_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e6138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/Chris/Desktop/To Submit/PythonEngineering/FinalProject/local_FinalProject/Sales-Forcasting-TabTransformer/data/raw/notebook_synthetic.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write CSV and point config \n",
    "synth_path = RAW_DIR / \"notebook_synthetic.csv\"\n",
    "synthetic_df.to_csv(synth_path, index=False)\n",
    "\n",
    "config[\"paths\"][\"raw_csv\"] = str(synth_path)\n",
    "synth_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:07:06,835 | INFO | src.data | Saved processed dataset to C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared dataset:\n",
      "X shape: (177, 18)\n",
      "y shape: (177,)\n",
      "Metadata keys: ['categorical_features', 'dates', 'feature_columns', 'horizon', 'numeric_features', 'stores', 'target']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  Store DayOfWeek Promo StateHoliday SchoolHoliday  Customers  Sales  \\\n",
       " 0     1         1     0            0             0        125   1025   \n",
       " 1     1         2     1            0             0        127   1033   \n",
       " 2     1         3     0            0             0        129   1041   \n",
       " 3     1         4     1            0             0        131   1049   \n",
       " 4     1         5     0            0             0        133   1057   \n",
       " \n",
       "    CompetitionDistance  Sales_lag_1  Sales_lag_7  Sales_lag_14  Sales_roll7  \\\n",
       " 0                410.0       1025.0       1025.0        1025.0       1025.0   \n",
       " 1                410.0       1025.0       1025.0        1025.0       1025.0   \n",
       " 2                410.0       1033.0       1025.0        1025.0       1029.0   \n",
       " 3                410.0       1041.0       1025.0        1025.0       1033.0   \n",
       " 4                410.0       1049.0       1025.0        1025.0       1037.0   \n",
       " \n",
       "    Sales_roll14  year  month  day  weekofyear  is_weekend  \n",
       " 0        1025.0  2024      1    1           1           0  \n",
       " 1        1025.0  2024      1    2           1           0  \n",
       " 2        1029.0  2024      1    3           1           0  \n",
       " 3        1033.0  2024      1    4           1           0  \n",
       " 4        1037.0  2024      1    5           1           0  ,\n",
       " 0    1033.0\n",
       " 1    1041.0\n",
       " 2    1049.0\n",
       " 3    1057.0\n",
       " 4    1065.0\n",
       " Name: Sales_target, dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare data - feature engineering, processed parquet, metadata\n",
    "X, y, metadata = data.load_sales_data(synth_path, config, save=True)\n",
    "print(\"Prepared dataset:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Metadata keys:\", sorted(list(metadata.keys())))\n",
    "\n",
    "# example data\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b0fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:07:11,401 | INFO | src.data | Loaded processed dataset from C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "2025-12-17 23:07:11,479 | INFO | src.train | Train split metrics:\n",
      "### train Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0000 |\n",
      "| RMSE | 0.0000 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0000 |\n",
      "2025-12-17 23:07:11,488 | INFO | src.train | Val split metrics:\n",
      "### val Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0000 |\n",
      "| RMSE | 0.0000 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0000 |\n",
      "2025-12-17 23:07:11,501 | INFO | src.train | Test split metrics:\n",
      "### test Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0000 |\n",
      "| RMSE | 0.0000 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0000 |\n",
      "2025-12-17 23:07:11,517 | INFO | src.train | Training complete. Artifacts stored in C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\artifacts\\linreg\n",
      "2025-12-17 23:07:11,519 | INFO | src.train | \n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0000 |\n",
      "| RMSE | 0.0000 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0000 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'artifacts': 'C:\\\\Users\\\\Chris\\\\Desktop\\\\To Submit\\\\PythonEngineering\\\\FinalProject\\\\local_FinalProject\\\\Sales-Forcasting-TabTransformer\\\\artifacts\\\\linreg',\n",
       " 'metrics': {'train': {'MAE': 1.0296166435165226e-13,\n",
       "   'RMSE': 1.530057909145519e-13,\n",
       "   'R2': 1.0,\n",
       "   'MAPE': 8.31513345406509e-15},\n",
       "  'val': {'MAE': 2.468628476240805e-13,\n",
       "   'RMSE': 2.549367812122855e-13,\n",
       "   'R2': 1.0,\n",
       "   'MAPE': 1.7801533498103764e-14},\n",
       "  'test': {'MAE': 3.9158799659667746e-13,\n",
       "   'RMSE': 4.0461442085989314e-13,\n",
       "   'R2': 1.0,\n",
       "   'MAPE': 2.638709813288198e-14}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train linear regression - baseline\n",
    "linreg_result = train.train_pipeline(config, \"linreg\")\n",
    "linreg_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53bb1f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:09:31,709 | INFO | src.data | Loaded processed dataset from C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "2025-12-17 23:09:32,623 | INFO | src.train | Train split metrics:\n",
      "### train Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0018 |\n",
      "| RMSE | 0.0023 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0001 |\n",
      "2025-12-17 23:09:32,643 | INFO | src.train | Val split metrics:\n",
      "### val Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 33.2048 |\n",
      "| RMSE | 43.1531 |\n",
      "| R2 | -0.7353 |\n",
      "| MAPE | 2.3551 |\n",
      "2025-12-17 23:09:32,658 | INFO | src.train | Test split metrics:\n",
      "### test Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 125.2503 |\n",
      "| RMSE | 130.5106 |\n",
      "| R2 | -13.4429 |\n",
      "| MAPE | 8.4213 |\n",
      "2025-12-17 23:09:32,689 | INFO | src.train | Training complete. Artifacts stored in C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\artifacts\\xgb\n",
      "2025-12-17 23:09:32,692 | INFO | src.train | \n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 33.2048 |\n",
      "| RMSE | 43.1531 |\n",
      "| R2 | -0.7353 |\n",
      "| MAPE | 2.3551 |\n"
     ]
    }
   ],
   "source": [
    "# train XGBoost - baseline\n",
    "try:\n",
    "    import xgboost  # noqa: F401\n",
    "    xgb_result = train.train_pipeline(config, \"xgb\")\n",
    "    xgb_result\n",
    "except Exception as exc:\n",
    "    print(\"Skipping XGBoost training (missing xgboost or error):\", exc)\n",
    "    xgb_result = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f4cf70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:09:35,290 | INFO | src.data | Loaded processed dataset from C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "c:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\src\\models\\tabtransformer.py:243: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=bool(training_config.get(\"amp\", False)))\n",
      "c:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\src\\models\\tabtransformer.py:255: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
      "2025-12-17 23:09:40,384 | INFO | src.train | Train split metrics:\n",
      "### train Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 1191.3484 |\n",
      "| RMSE | 1194.2878 |\n",
      "| R2 | -202.4267 |\n",
      "| MAPE | 99.6826 |\n",
      "2025-12-17 23:09:40,403 | INFO | src.train | Val split metrics:\n",
      "### val Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 1380.2350 |\n",
      "| RMSE | 1380.6240 |\n",
      "| R2 | -1775.2544 |\n",
      "| MAPE | 99.7299 |\n",
      "2025-12-17 23:09:40,425 | INFO | src.train | Test split metrics:\n",
      "### test Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 1474.2630 |\n",
      "| RMSE | 1474.6631 |\n",
      "| R2 | -1842.9496 |\n",
      "| MAPE | 99.7470 |\n",
      "2025-12-17 23:09:40,463 | INFO | src.train | Training complete. Artifacts stored in C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\artifacts\\tabtx\n",
      "2025-12-17 23:09:40,465 | INFO | src.train | \n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 1380.2350 |\n",
      "| RMSE | 1380.6240 |\n",
      "| R2 | -1775.2544 |\n",
      "| MAPE | 99.7299 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'artifacts': 'C:\\\\Users\\\\Chris\\\\Desktop\\\\To Submit\\\\PythonEngineering\\\\FinalProject\\\\local_FinalProject\\\\Sales-Forcasting-TabTransformer\\\\artifacts\\\\tabtx',\n",
       " 'metrics': {'train': {'MAE': 1191.3483849224056,\n",
       "   'RMSE': 1194.2878388329668,\n",
       "   'R2': -202.42672776345887,\n",
       "   'MAPE': 99.68259578907653},\n",
       "  'val': {'MAE': 1380.2350244522095,\n",
       "   'RMSE': 1380.6239753505224,\n",
       "   'R2': -1775.2544369144703,\n",
       "   'MAPE': 99.7298529438007},\n",
       "  'test': {'MAE': 1474.2629908919334,\n",
       "   'RMSE': 1474.663075574742,\n",
       "   'R2': -1842.94956455361,\n",
       "   'MAPE': 99.7470097528111}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train TabTransformer\n",
    "tabtx_result = train.train_pipeline(config, \"tabtx\")\n",
    "tabtx_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20225402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:09:47,829 | INFO | src.data | Loaded processed dataset from C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "2025-12-17 23:09:51,644 | INFO | src.evaluate | Evaluation metrics (test):\n",
      "### test Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0000 |\n",
      "| RMSE | 0.0000 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0000 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LINREG (TEST) ===\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 0.0000 |\n",
      "| RMSE | 0.0000 |\n",
      "| R2 | 1.0000 |\n",
      "| MAPE | 0.0000 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetricsReport(values={'MAE': 3.9158799659667746e-13, 'RMSE': 4.0461442085989314e-13, 'R2': 1.0, 'MAPE': 2.638709813288198e-14}, label='LINREG Test')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:09:51,657 | INFO | src.data | Loaded processed dataset from C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "2025-12-17 23:09:52,237 | INFO | src.evaluate | Evaluation metrics (test):\n",
      "### test Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 125.2503 |\n",
      "| RMSE | 130.5106 |\n",
      "| R2 | -13.4429 |\n",
      "| MAPE | 8.4213 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGB (TEST) ===\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 125.2503 |\n",
      "| RMSE | 130.5106 |\n",
      "| R2 | -13.4429 |\n",
      "| MAPE | 8.4213 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetricsReport(values={'MAE': 125.25029161241319, 'RMSE': 130.5106485922041, 'R2': -13.442930522293207, 'MAPE': 8.421305042729404}, label='XGB Test')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 23:09:52,252 | INFO | src.data | Loaded processed dataset from C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "c:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\src\\models\\tabtransformer.py:338: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  payload = torch.load(path, map_location=\"cpu\")\n",
      "2025-12-17 23:09:52,986 | INFO | src.evaluate | Evaluation metrics (test):\n",
      "### test Metrics\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 1474.2630 |\n",
      "| RMSE | 1474.6631 |\n",
      "| R2 | -1842.9496 |\n",
      "| MAPE | 99.7470 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TABTX (TEST) ===\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| MAE | 1474.2630 |\n",
      "| RMSE | 1474.6631 |\n",
      "| R2 | -1842.9496 |\n",
      "| MAPE | 99.7470 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetricsReport(values={'MAE': 1474.2629908919334, 'RMSE': 1474.663075574742, 'R2': -1842.94956455361, 'MAPE': 99.7470097528111}, label='TABTX Test')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'linreg': {'MAE': 3.9158799659667746e-13,\n",
       "  'RMSE': 4.0461442085989314e-13,\n",
       "  'R2': 1.0,\n",
       "  'MAPE': 2.638709813288198e-14},\n",
       " 'xgb': {'MAE': 125.25029161241319,\n",
       "  'RMSE': 130.5106485922041,\n",
       "  'R2': -13.442930522293207,\n",
       "  'MAPE': 8.421305042729404},\n",
       " 'tabtx': {'MAE': 1474.2629908919334,\n",
       "  'RMSE': 1474.663075574742,\n",
       "  'R2': -1842.94956455361,\n",
       "  'MAPE': 99.7470097528111}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model evaluation by test split and show metrics table\n",
    "results = {}\n",
    "\n",
    "for model_name in [\"linreg\", \"xgb\", \"tabtx\"]:\n",
    "    if model_name == \"xgb\" and xgb_result is None:\n",
    "        continue\n",
    "    metric_values = evaluate.evaluate_pipeline(config, model_name, split=\"test\")\n",
    "    results[model_name] = metric_values\n",
    "\n",
    "    print(f\"\\n=== {model_name.upper()} (TEST) ===\")\n",
    "    print(metrics_table(metric_values))\n",
    "    try:\n",
    "        display(MetricsReport(metric_values, label=f\"{model_name.upper()} Test\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8956e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Metrics (LinReg + TabTransformer):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetricsReport(values={'R2': -920.974782276805, 'MAE': 737.131495445967, 'RMSE': 737.3315377873712, 'MAPE': 49.87350487640556}, label='Linear Regression')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'R2': -920.974782276805,\n",
       " 'MAE': 737.131495445967,\n",
       " 'RMSE': 737.3315377873712,\n",
       " 'MAPE': 49.87350487640556}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate MetricsReport usage (operator overloading & aggregation)\n",
    "linreg_report = MetricsReport(results[\"linreg\"], label=\"Linear Regression\")\n",
    "tabtx_report  = MetricsReport(results[\"tabtx\"], label=\"TabTransformer\")\n",
    "\n",
    "# example: average metrics across two models\n",
    "avg_report = (linreg_report + tabtx_report) / 2\n",
    "\n",
    "print(\"Averaged Metrics (LinReg + TabTransformer):\")\n",
    "display(avg_report)\n",
    "\n",
    "# access as dictionary if needed\n",
    "avg_report.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0301ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions to: C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\artifacts\\notebook_preds.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1040.396014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046.311353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1052.226692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058.142030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1064.057369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction\n",
       "0  1040.396014\n",
       "1  1046.311353\n",
       "2  1052.226692\n",
       "3  1058.142030\n",
       "4  1064.057369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on the csv and write preds to a file\n",
    "output_preds_path = ARTIFACTS_DIR / \"notebook_preds.csv\"\n",
    "\n",
    "# demonstrate prediction + file I/O using a single model - same API works for \"xgb\" and \"tabtx\".\n",
    "PRED_MODEL = \"linreg\"\n",
    "\n",
    "artifact_dir = utils.get_artifact_dir(config, PRED_MODEL)\n",
    "model = evaluate.load_trained_model(PRED_MODEL, artifact_dir, config)\n",
    "\n",
    "# load features \n",
    "X_full, y_full, metadata_full = data.load_sales_data(synth_path, config, save=False)\n",
    "\n",
    "preds = model.predict(X_full)\n",
    "preds_df = pd.DataFrame({\"prediction\": preds.values}, index=X_full.index)\n",
    "preds_df.to_csv(output_preds_path, index=False)\n",
    "\n",
    "print(\"Wrote predictions to:\", output_preds_path)\n",
    "preds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab3096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files created under artifacts/linreg:\n",
      " - config_snapshot.json\n",
      " - metrics.json\n",
      " - metrics_test.json\n",
      " - model.joblib\n",
      " - pred_vs_actual.png\n",
      " - residual_hist.png\n"
     ]
    }
   ],
   "source": [
    "# demonstrate file I/O side effects (artifacts created by the pipeline)\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Files created under artifacts/linreg:\")\n",
    "artifact_dir = Path(\"artifacts/linreg\")\n",
    "if artifact_dir.exists():\n",
    "    for f in sorted(artifact_dir.iterdir()):\n",
    "        print(\" -\", f.name)\n",
    "else:\n",
    "    print(\" (artifacts/linreg does not exist yet â€” train/eval linreg first)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed4b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed parquet exists: True -> C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\data\\processed\\sales_processed.parquet\n",
      "\n",
      "Artifacts directory contents:\n",
      "- linreg -> ['config_snapshot.json', 'metrics.json', 'metrics_test.json', 'model.joblib', 'pred_vs_actual.png', 'residual_hist.png'] ...\n",
      "- notebook_preds.csv\n",
      "- tabtx -> ['config_snapshot.json', 'metrics.json', 'metrics_test.json', 'model.pt', 'pred_vs_actual.png', 'residual_hist.png'] ...\n",
      "- xgb -> ['config_snapshot.json', 'metrics.json', 'metrics_test.json', 'model.joblib', 'pred_vs_actual.png', 'residual_hist.png'] ...\n"
     ]
    }
   ],
   "source": [
    "# outputs\n",
    "processed_path = PROCESSED_DIR / config[\"paths\"].get(\"processed_filename\", \"sales.parquet\")\n",
    "print(\"Processed parquet exists:\", processed_path.exists(), \"->\", processed_path)\n",
    "\n",
    "print(\"\\nArtifacts directory contents:\")\n",
    "for p in sorted(ARTIFACTS_DIR.glob(\"*\")):\n",
    "    if p.is_dir():\n",
    "        print(\"-\", p.name, \"->\", [x.name for x in sorted(p.iterdir())][:10], \"...\")\n",
    "    else:\n",
    "        print(\"-\", p.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7c0ff",
   "metadata": {},
   "source": [
    "## Experiment Name Support (Artifact Isolation)\n",
    "\n",
    "This section demonstrates that setting `experiment_name` in the YAML configuration\n",
    "automatically changes where model artifacts are written. This allows multiple\n",
    "experiments to coexist without overwriting results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfe838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured experiment_name: None\n",
      "Resolved artifact directory:\n",
      "  C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\artifacts\\linreg\n",
      "\n",
      "Directory contents:\n",
      " - config_snapshot.json\n",
      " - metrics.json\n",
      " - metrics_test.json\n",
      " - model.joblib\n",
      " - pred_vs_actual.png\n",
      " - residual_hist.png\n"
     ]
    }
   ],
   "source": [
    "print(\"Configured experiment_name:\", config.get(\"experiment_name\"))\n",
    "artifact_dir = utils.get_artifact_dir(config, \"linreg\")\n",
    "print(\"Resolved artifact directory:\")\n",
    "print(\" \", artifact_dir)\n",
    "print(\"\\nDirectory contents:\")\n",
    "if artifact_dir.exists():\n",
    "    for f in sorted(artifact_dir.iterdir()):\n",
    "        print(\" -\", f.name)\n",
    "else:\n",
    "    print(\" (artifact directory does not exist yet)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ddc4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternate experiment_name: notebook_experiment_alt\n",
      "Alternate artifact dir: C:\\Users\\Chris\\Desktop\\To Submit\\PythonEngineering\\FinalProject\\local_FinalProject\\Sales-Forcasting-TabTransformer\\artifacts\\linreg\n"
     ]
    }
   ],
   "source": [
    "# simulate a second experiment in-notebook\n",
    "config_alt = dict(config)\n",
    "config_alt[\"experiment_name\"] = \"notebook_experiment_alt\"\n",
    "alt_dir = utils.get_artifact_dir(config_alt, \"linreg\")\n",
    "print(\"Alternate experiment_name:\", config_alt[\"experiment_name\"])\n",
    "print(\"Alternate artifact dir:\", alt_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
